{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distributed MPC for cooperation scheme using artificial references.\n",
    "The goal is to implement consensus of a multi-agents system.\n",
    "\n",
    "$m$ agents with dynamics $x_i(t+1) = f(x_i(t), u_i(t))$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement a sequential scheme as outlined in the corresponding manuscript:\n",
    "\n",
    ">M. Köhler, M. A. Müller, and F. Allgöwer, \"Distributed MPC for Self-Organized Cooperation of Multi-Agent Systems,\", 2023, available on arxiv. doi: 10.48550/arXiv.2210.10128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mkmpc\n",
    "import numpy as np\n",
    "import casadi as cas\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a multi-agent system comprising four to five two-dimensional double integrators.\n",
    "(We will add the fifth one later to the simulation, but will initialise it now.)\n",
    "That is $f_i(x_i, u_i) = A_i x_i + B_i u_i$ with\n",
    "\n",
    "$A_{i} = \\begin{bmatrix} 1 & 0 & 1 & 0 \\\\ 0 & 1 & 0 & 1 \\\\ 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 1 \\end{bmatrix}$ and $B_{i} = \\begin{bmatrix} 0 & 0 \\\\ 0 & 0 \\\\ 1 & 0\\\\ 0 & 1 \\end{bmatrix}$.\n",
    "\n",
    "The output are the first two states, i.e. $y_i = \\begin{bmatrix} x_{i,1} \\\\ x_{i,2} \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 5  # Set number of agents.\n",
    "state_dims = [4, 4, 4, 4, 4]  # Set the state dimensions.\n",
    "input_dims = [2, 2, 2, 2, 2]  # Set the input dimensions.\n",
    "output_dim = 2  # Set the output dimension, which is the same for all agents.\n",
    "\n",
    "# Specifiy initial states.\n",
    "initial_state_list = [np.array([[0], [0], [0], [0]]),\n",
    "                      np.array([[0], [0], [0], [0]]),\n",
    "                      np.array([[0], [0], [0], [0]]),\n",
    "                      np.array([[0], [0], [0], [0]])]\n",
    "\n",
    "dynamics_list = []\n",
    "output_maps = []\n",
    "for i in range(num_agents):\n",
    "    x = cas.MX.sym('x', state_dims[i])  # Create symbolic for state.\n",
    "    u = cas.MX.sym('u', input_dims[i])  # Create symbolic for input.\n",
    "    A = np.array([[1, 0, 1, 0],\n",
    "                  [0, 1, 0, 1],\n",
    "                  [0, 0, 1, 0],\n",
    "                  [0, 0, 0, 1]])\n",
    "    B = np.array([[0, 0],\n",
    "                  [0, 0],\n",
    "                  [1, 0],\n",
    "                  [0, 1]])\n",
    "    # Create state dynamics as a casadi function.\n",
    "    dynamics_list.append(cas.Function('dynamics', [x,u], [A@x + B@u], ['x', 'u'], ['f']))\n",
    "    # Create output map as a casadi function.\n",
    "    C = np.array([[1, 0, 0, 0],\n",
    "                  [0, 1, 0, 0]])\n",
    "    output_maps.append(cas.Function('output', [x,u], [C@x], ['x', 'u'], ['h']))\n",
    "    \n",
    "# Define the agents.\n",
    "agents = []\n",
    "for i in range(num_agents):\n",
    "    # Initialise the agent.\n",
    "    agents.append(mkmpc.agent(id = i+1, state_dim = state_dims[i], input_dim = input_dims[i],\n",
    "                              dynamics = dynamics_list[i], initial_time=0, initial_state=initial_state_list[0],\n",
    "                              output_map=output_maps[i], output_dim=output_dim))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set constraints for each agent and visualise them.\n",
    "\n",
    "For simplicity, we use polytopes for the first two states.\n",
    "We use vertex notation for plotting and half-space notation for the optimization.\n",
    "\n",
    "- $\\mathbb{X}_1 = \\mathrm{co} \\{ \\begin{bmatrix} 1.1 \\\\ -2.1 \\end{bmatrix}, \\begin{bmatrix} 1.1 \\\\ 4.1 \\end{bmatrix} , \\begin{bmatrix} -1.1 \\\\ 4.1 \\end{bmatrix} , \\begin{bmatrix} -1.1 \\\\ -2.1 \\end{bmatrix}  \\} = \\{ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\mid \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\le \\begin{bmatrix}  2.1 \\\\ 1.1 \\\\ 4.1 \\\\ 1.1 \\end{bmatrix}$\n",
    "- $\\mathbb{X}_2 = \\mathbb{X}_3 = \\mathrm{co} \\{ \\begin{bmatrix} 4.1 \\\\ -2.1 \\end{bmatrix}, \\begin{bmatrix} 4.1 \\\\ 2.1 \\end{bmatrix} , \\begin{bmatrix} -1.1 \\\\ 2.1 \\end{bmatrix} , \\begin{bmatrix} -1.1 \\\\ -2.1 \\end{bmatrix}  \\} = \\{ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\mid \\begin{bmatrix} -1 & 0 \\\\ 1 & 0 \\\\ 0 & -1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\le \\begin{bmatrix}  1.1 \\\\ 4.1 \\\\ 2.1 \\\\ 2.1 \\end{bmatrix}$\n",
    "- $\\mathbb{X}_4 = \\mathbb{X}_5 = \\mathrm{co} \\{ \\begin{bmatrix} 3.1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 3.1 \\end{bmatrix} , \\begin{bmatrix} -3.1 \\\\ 0 \\end{bmatrix} , \\begin{bmatrix} 0 \\\\ -3.1 \\end{bmatrix}  \\} = \\{ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\mid \\begin{bmatrix} 1 & -1 \\\\ 1 & 1 \\\\ -1 & 1 \\\\ -1 & -1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\le \\begin{bmatrix}  3.1 \\\\ 3.1 \\\\ 3.1 \\\\ 3.1 \\end{bmatrix} $\n",
    "\n",
    "We constrain the third and fourth state as well as the inputs between $-0.25$ and $0.25$ for all agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set constraints for each agent.\n",
    "box_input_constr = np.array([[-0.25, 0.25]])  # Define input constraints for all agents.\n",
    "\n",
    "agents[0].set_constraints(box_input_constraints=box_input_constr)  # Set input constraints.\n",
    "# Set state constraints:\n",
    "agents[0].state_constraints[\"A\"] = np.array([[0, -1, 0, 0],\n",
    "                                             [1, 0, 0, 0],\n",
    "                                             [0, 1, 0, 0],\n",
    "                                             [-1, 0, 0, 0],\n",
    "                                             [0, 0, 1, 0],  # Constraints for 3rd and 4th state from here.\n",
    "                                             [0, 0, -1, 0],\n",
    "                                             [0, 0, 0, 1],\n",
    "                                             [0, 0, 0, -1]\n",
    "                                            ]) \n",
    "agents[0].state_constraints[\"b\"] = np.array([[2.1], [1.1], [4.1], [1.1], [0.25], [0.25], [0.25], [0.25]])\n",
    "\n",
    "agents[1].set_constraints(box_input_constraints=box_input_constr)  # Set input constraints.\n",
    "# Set state constraints:\n",
    "agents[1].state_constraints[\"A\"] = np.array([[-1, 0, 0, 0],\n",
    "                                             [1, 0, 0, 0],\n",
    "                                             [0, -1, 0, 0],\n",
    "                                             [0, 1, 0, 0],\n",
    "                                             [0, 0, 1, 0],  # Constraints for 3rd and 4th state from here.\n",
    "                                             [0, 0, -1, 0],\n",
    "                                             [0, 0, 0, 1],\n",
    "                                             [0, 0, 0, -1]\n",
    "                                            ]) \n",
    "agents[1].state_constraints[\"b\"] = np.array([[1.1], [4.1], [2.1], [2.1], [0.25], [0.25], [0.25], [0.25]])\n",
    "\n",
    "agents[2].set_constraints(box_input_constraints=box_input_constr)  # Set input constraints.\n",
    "# Set state constraints:\n",
    "agents[2].state_constraints[\"A\"] = np.array([[-1, 0, 0, 0],\n",
    "                                             [1, 0, 0, 0],\n",
    "                                             [0, -1, 0, 0],\n",
    "                                             [0, 1, 0, 0],\n",
    "                                             [0, 0, 1, 0],  # Constraints for 3rd and 4th state from here.\n",
    "                                             [0, 0, -1, 0],\n",
    "                                             [0, 0, 0, 1],\n",
    "                                             [0, 0, 0, -1]\n",
    "                                            ]) \n",
    "agents[2].state_constraints[\"b\"] = np.array([[1.1], [4.1], [2.1], [2.1], [0.25], [0.25], [0.25], [0.25]])\n",
    "\n",
    "agents[3].set_constraints(box_input_constraints=box_input_constr)  # Set input constraints.\n",
    "# Set state constraints:\n",
    "agents[3].state_constraints[\"A\"] = np.array([[1, -1, 0, 0],\n",
    "                                             [1, 1, 0, 0],\n",
    "                                             [-1, 1, 0, 0],\n",
    "                                             [-1, -1, 0, 0],\n",
    "                                             [0, 0, 1, 0],  # Constraints for 3rd and 4th state from here.\n",
    "                                             [0, 0, -1, 0],\n",
    "                                             [0, 0, 0, 1],\n",
    "                                             [0, 0, 0, -1]\n",
    "                                            ]) \n",
    "agents[3].state_constraints[\"b\"] = np.array([[3.1], [3.1], [3.1], [3.1], [0.25], [0.25], [0.25], [0.25]])\n",
    "\n",
    "agents[4].set_constraints(box_input_constraints=box_input_constr)  # Set input constraints.\n",
    "# Set state constraints:\n",
    "agents[4].state_constraints[\"A\"] = np.array([[1, -1, 0, 0],\n",
    "                                                  [1, 1, 0, 0],\n",
    "                                                  [-1, 1, 0, 0],\n",
    "                                                  [-1, -1, 0, 0],\n",
    "                                                  [0, 0, 1, 0],  # Constraints for 3rd and 4th state from here.\n",
    "                                                  [0, 0, -1, 0],\n",
    "                                                  [0, 0, 0, 1],\n",
    "                                                  [0, 0, 0, -1]\n",
    "                                                 ])  \n",
    "agents[4].state_constraints[\"b\"] = np.array([[3.1], [3.1], [3.1], [3.1], [0.25], [0.25], [0.25], [0.25]])\n",
    "\n",
    "## Visualise constraints on the first two states. For simplicity, use the vertices.\n",
    "# Note that the inequality constraints above need to correspond to the following vertices.\n",
    "\n",
    "agents[0].state_constraints_for_plot = np.array([[1.1,1.1,-1.1,-1.1],[-2.1,4.1,4.1,-2.1]])\n",
    "agents[1].state_constraints_for_plot = np.array([[4.1,4.1,-1.1,-1.1],[-2.1,2.1,2.1,-2.1]])\n",
    "agents[2].state_constraints_for_plot = np.array([[4.1,4.1,-1.1,-1.1],[-2.1,2.1,2.1,-2.1]])\n",
    "agents[3].state_constraints_for_plot = np.array([[3.1,0,-3.1,0],[0,3.1,0,-3.1]])\n",
    "agents[4].state_constraints_for_plot = np.array([[3.1,0,-3.1,0],[0,3.1,0,-3.1]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(True, which='both')  # Draw grid lines.\n",
    "ax.axis('equal')  # Make plot a box.\n",
    "ax.fill(agents[0].state_constraints_for_plot[0,:], agents[0].state_constraints_for_plot[1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0,0,0.9,0.5))  # Draw polyhedra.\n",
    "ax.fill(agents[1].state_constraints_for_plot[0,:], agents[1].state_constraints_for_plot[1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0,0.9,0,0.5))  # Draw polyhedra.\n",
    "ax.fill(agents[3].state_constraints_for_plot[0,:], agents[3].state_constraints_for_plot[1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0.9,0,0,0.5))  # Draw polyhedra.\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set neighbours as\n",
    "* $\\mathcal{N}_1 = \\{2, 4\\}$\n",
    "* $\\mathcal{N}_2 = \\{1\\}$\n",
    "* $\\mathcal{N}_3 = \\{4\\}$\n",
    "* $\\mathcal{N}_4 = \\{3, 1\\}$\n",
    "\n",
    "The graph changes when the fifth agents joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set neighbours in lists as described above. Note that the index starts at 0.\n",
    "agents[0].neighbours = [agents[1], agents[3]]\n",
    "agents[1].neighbours = [agents[0]]\n",
    "agents[2].neighbours = [agents[3]]\n",
    "agents[3].neighbours = [agents[0], agents[2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the stage cost for tracking, i.e. $l_i = \\Vert x_i - x_{\\mathrm{c},i} \\Vert^2_{Q_i} + \\Vert u_i - u_{\\mathrm{c},i} \\Vert^2_{R_i}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_agents):\n",
    "    # Define the artificial equilibrium. \n",
    "    x = cas.MX.sym('x', state_dims[i])\n",
    "    u = cas.MX.sym('u', input_dims[i])\n",
    "    xc = cas.MX.sym('x_c', state_dims[i])\n",
    "    uc = cas.MX.sym('u_c', input_dims[i])\n",
    "    \n",
    "    # Set the weight for the distance of the state to the equilibrium.\n",
    "    Q = np.eye(state_dims[i])\n",
    "    # Set the weight for the distance of the input to the equilibrium.\n",
    "    R = np.eye(input_dims[i])\n",
    "    \n",
    "    stage_cost = cas.Function('stage_cost', [x, u, xc, uc], [ (x - xc).T@Q@(x - xc) + (u - uc).T@R@(u - uc) ],\n",
    "                              ['x', 'u', 'xc', 'uc'], ['l'])\n",
    "    \n",
    "    # Add stage cost to agents.\n",
    "    agents[i].stage_cost = stage_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the cost for cooperation.\n",
    "\n",
    "We want to have consensus in the outputs.\n",
    "As the bilateral costs we take $V_{ij}^\\mathrm{c} = \\Vert y_{\\mathrm{c},i} - y_{\\mathrm{c},j} \\Vert^2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yc1 = cas.MX.sym('yc1', output_dim)\n",
    "yc2 = cas.MX.sym('yc2', output_dim)\n",
    "bilat_coop_cost = cas.Function('cooperation_cost', [yc1, yc2], [ (yc1 - yc2).T@(yc1 - yc2)], ['yc1', 'yc2'], ['V_ij^c'])\n",
    "# Set the bilateral cooperation cost for each agent.\n",
    "for agent in agents:\n",
    "    agent.bilat_coop_cost = bilat_coop_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the set of admissible cooperation outputs $\\mathcal{Y}_i$ to be almost the same as the state constraint sets for the first two states.\n",
    "\n",
    "Define the sets again for computations in half-space form and for plotting in vertex form.\n",
    "\n",
    "\n",
    "- $\\mathcal{Y}_1 = \\mathrm{co} \\{ \\begin{bmatrix} 1 \\\\ -2 \\end{bmatrix}, \\begin{bmatrix} 1 \\\\ 4 \\end{bmatrix} , \\begin{bmatrix} -1 \\\\ 4 \\end{bmatrix} , \\begin{bmatrix} -1 \\\\ -2 \\end{bmatrix}  \\} = \\{ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\mid \\begin{bmatrix} 0 & -1 \\\\ 1 & 0 \\\\ 0 & 1 \\\\ -1 & 0 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\le \\begin{bmatrix}  2 \\\\ 1 \\\\ 4 \\\\ 1 \\end{bmatrix}$\n",
    "- $\\mathcal{Y}_2 = \\mathcal{Y}_3 = \\mathrm{co} \\{ \\begin{bmatrix} 4 \\\\ -2 \\end{bmatrix}, \\begin{bmatrix} 4 \\\\ 2 \\end{bmatrix} , \\begin{bmatrix} -1 \\\\ 2 \\end{bmatrix} , \\begin{bmatrix} -1 \\\\ -2 \\end{bmatrix}  \\} = \\{ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\mid \\begin{bmatrix} -1 & 0 \\\\ 1 & 0 \\\\ 0 & -1 \\\\ 0 & 1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\le \\begin{bmatrix}  1 \\\\ 4 \\\\ 2 \\\\ 2 \\end{bmatrix}$\n",
    "- $\\mathcal{Y}_4 = \\mathcal{Y}_5 = \\mathrm{co} \\{ \\begin{bmatrix} 3 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 3 \\end{bmatrix} , \\begin{bmatrix} -3 \\\\ 0 \\end{bmatrix} , \\begin{bmatrix} 0 \\\\ -3 \\end{bmatrix}  \\} = \\{ \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\mid \\begin{bmatrix} 1 & -1 \\\\ 1 & 1 \\\\ -1 & 1 \\\\ -1 & -1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} \\le \\begin{bmatrix}  3 \\\\ 3 \\\\ 3 \\\\ 3 \\end{bmatrix} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new attribute to the agents, a dictionary that contains the above matrices. \n",
    "\n",
    "agents[0].cooperation_output_constraint = {}\n",
    "agents[0].cooperation_output_constraint[\"A\"] = np.array([[0, -1],\n",
    "                                                  [1, 0],\n",
    "                                                  [0, 1],\n",
    "                                                  [-1, 0]\n",
    "                                                 ]) \n",
    "agents[0].cooperation_output_constraint[\"b\"] = np.array([[2], [1], [4], [1]])\n",
    "\n",
    "agents[1].cooperation_output_constraint = {}\n",
    "agents[1].cooperation_output_constraint[\"A\"] = np.array([[-1, 0],\n",
    "                                                  [1, 0],\n",
    "                                                  [0, -1],\n",
    "                                                  [0, 1]\n",
    "                                                 ]) \n",
    "agents[1].cooperation_output_constraint[\"b\"] = np.array([[1], [4], [2], [2]])\n",
    "\n",
    "agents[2].cooperation_output_constraint = {}\n",
    "agents[2].cooperation_output_constraint[\"A\"] = np.array([[-1, 0],\n",
    "                                                  [1, 0],\n",
    "                                                  [0, -1],\n",
    "                                                  [0, 1]\n",
    "                                                 ]) \n",
    "agents[2].cooperation_output_constraint[\"b\"] = np.array([[1], [4], [2], [2]])\n",
    "\n",
    "agents[3].cooperation_output_constraint = {}\n",
    "agents[3].cooperation_output_constraint[\"A\"] = np.array([[1, -1],\n",
    "                                                  [1, 1],\n",
    "                                                  [-1, 1],\n",
    "                                                  [-1, -1]\n",
    "                                                 ]) \n",
    "agents[3].cooperation_output_constraint[\"b\"] = np.array([[3], [3], [3], [3]])\n",
    "\n",
    "agents[4].cooperation_output_constraint = {}\n",
    "agents[4].cooperation_output_constraint[\"A\"] = np.array([[1, -1],\n",
    "                                                  [1, 1],\n",
    "                                                  [-1, 1],\n",
    "                                                  [-1, -1]\n",
    "                                                 ])  \n",
    "agents[4].cooperation_output_constraint[\"b\"] = np.array([[3], [3], [3], [3]])\n",
    "\n",
    "## Visualise constraints on the first two states. For simplicity, use the vertices.\n",
    "# Note that the inequality constraints above need to correspond to the following vertices.\n",
    "\n",
    "agents[0].cooperation_output_constraint[\"vertex_mat\"] = np.array([[1,1,-1,-1],[-2,4,4,-2]])\n",
    "agents[1].cooperation_output_constraint[\"vertex_mat\"] = np.array([[4,4,-1,-1],[-2,2,2,-2]])\n",
    "agents[2].cooperation_output_constraint[\"vertex_mat\"] = np.array([[4,4,-1,-1],[-2,2,2,-2]])\n",
    "agents[3].cooperation_output_constraint[\"vertex_mat\"] = np.array([[3,0,-3,0],[0,3,0,-3]])\n",
    "agents[4].cooperation_output_constraint[\"vertex_mat\"] = np.array([[3,0,-3,0],[0,3,0,-3]])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.grid(True, which='both')  # Draw grid lines.\n",
    "ax.axis('equal')  # Make plot a box.\n",
    "ax.fill(agents[0].cooperation_output_constraint[\"vertex_mat\"][0,:], agents[0].cooperation_output_constraint[\"vertex_mat\"][1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0,0,0.9,0.5))  # Draw polyhedra.\n",
    "ax.fill(agents[1].cooperation_output_constraint[\"vertex_mat\"][0,:], agents[1].cooperation_output_constraint[\"vertex_mat\"][1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0,0.9,0,0.5))  # Draw polyhedra.\n",
    "ax.fill(agents[3].cooperation_output_constraint[\"vertex_mat\"][0,:], agents[3].cooperation_output_constraint[\"vertex_mat\"][1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0.9,0,0,0.5))  # Draw polyhedra.\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up the sequential MPC scheme."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set simulation and MPC parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_simulation_time = 40\n",
    "horizon = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation of all agents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set all cooperation outputs to zero for the initialisation since 0 is an admissible cooperation output for all agents.\n",
    "for agent in agents:\n",
    "    agent.current_cooperation_output = np.zeros((agent.output_dim, 1))\n",
    "\n",
    "# Set initial states.\n",
    "agents[0].current_state = np.array([[-1], [4], [0], [0]])\n",
    "agents[1].current_state = np.array([[2], [1.8], [0], [0]])\n",
    "agents[2].current_state = np.array([[3], [-1.5], [0], [0]])\n",
    "agents[3].current_state = np.array([[-2], [0], [0], [0]])\n",
    "agents[4].current_state = np.array([[0], [-2], [0], [0]])\n",
    "\n",
    "# Solve the optimisation problem for all agents.\n",
    "for agent in agents:\n",
    "    agent.current_MPC_sol = mkmpc.MPC_for_cooperation(agent, horizon=horizon)\n",
    "    \n",
    "# Set resulting optimal cooperation output as initial cooperation output.\n",
    "for agent in agents:\n",
    "    agent.current_cooperation_output = agent.current_MPC_sol[\"yc_opt\"]\n",
    "\n",
    "# Set initial state as current cooperation output.\n",
    "for agent in agents:\n",
    "    agent.current_cooperation_output = agent.current_state[0:2]\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the initial solution.\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "for agent in agents:\n",
    "    #fig, ax = plt.subplots()  # Uncomment to show individual plots.\n",
    "    time_steps = range(0, horizon+1)\n",
    "    label_str = \"agent \" + agent.id  # For labelling the plot.\n",
    "    ax.plot(agent.current_MPC_sol[\"x_opt\"][0,:], agent.current_MPC_sol[\"x_opt\"][1,:], label=label_str, marker='x', markersize=5)\n",
    "    ax.grid(True, which='both')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MPC algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep track of the closed-loop system.\n",
    "closed_loop_evolution = []\n",
    "time_step_for_change = 19  # Set the time step where the system changes.\n",
    "\n",
    "# Create a list containing the agents that are included in the multi-agent system.\n",
    "agents_in_system = []\n",
    "for i in [0,1,2,3]:\n",
    "    agents_in_system.append(agents[i])\n",
    "\n",
    "for t in range(0, last_simulation_time + 1):\n",
    "    # Track the time.\n",
    "    closed_loop_evolution.append([None]*len(agents))\n",
    "    \n",
    "    # Go in sequence over the agents.\n",
    "    for agent in agents_in_system:\n",
    "        closed_loop_evolution[t][agents.index(agent)] = {\"time\":t}\n",
    "        agent.current_time = t    \n",
    "        \n",
    "        # Keep track of the current state.\n",
    "        closed_loop_evolution[t][agents.index(agent)].update({\"current_state\":agent.current_state})\n",
    "        \n",
    "        # Solve the MPC problem.\n",
    "        agent.current_MPC_sol = mkmpc.MPC_for_cooperation(agent, horizon=horizon)\n",
    "        # Keep track of the solution.\n",
    "        closed_loop_evolution[t][agents.index(agent)].update(agent.current_MPC_sol)\n",
    "        # Update the current state of the agent. \n",
    "        # Without model errors and satisfaction of the dynamic constraint, the next predicted state will be the next closed-loop state.\n",
    "        agent.current_state = agent.current_MPC_sol[\"x_opt\"][0:agent.state_dim, 1:2]\n",
    "        # Update the cooperation output of the agent.\n",
    "        agent.current_cooperation_output = agent.current_MPC_sol[\"yc_opt\"]\n",
    "            \n",
    "    # For plotting, pad the times agents were inactive.\n",
    "    agents_not_in_system = [agent for agent in agents if agent not in agents_in_system]\n",
    "    for agent in agents_not_in_system:\n",
    "        closed_loop_evolution[t][agents.index(agent)] = {\"time\":t}\n",
    "        agent.current_time = t  # Update the agents time.\n",
    "        closed_loop_evolution[t][agents.index(agent)].update({\"current_state\":agent.current_state})  # Save the current (unchanged) state.\n",
    "    \n",
    "    # Change the system at a specified timestep.\n",
    "    if t == time_step_for_change:\n",
    "        # Add agent to optimisation sequence.\n",
    "        agents_in_system.append(agents[4])\n",
    "        # Update neighbours.\n",
    "        agents[0].neighbours = [agents[3]]\n",
    "        agents[1].neighbours = [agents[2]]\n",
    "        agents[2].neighbours = [agents[1], agents[3], agents[4]]\n",
    "        agents[3].neighbours = [agents[0], agents[2], agents[4]]\n",
    "        agents[4].neighbours = [agents[3], agents[2]]      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plots\n",
    "#### Plot the closed-loop evolution.\n",
    "Note that the figures in the paper were created using a different work flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_steps = range(0, last_simulation_time+1)\n",
    "\n",
    "fig1, ax1 = plt.subplots()\n",
    "ax1.grid(True)\n",
    "fig2, ax2 = plt.subplots()\n",
    "ax2.grid(True)\n",
    "fig3, ax3 = plt.subplots()\n",
    "ax3.grid(True)\n",
    "\n",
    "line_styles = ['solid', 'dotted', 'dashdot', 'dashed', (0, (3, 1, 1, 1, 1, 1))]\n",
    "colour_styles = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple']\n",
    "\n",
    "for agent in agents:\n",
    "    # Extract state evolution of agent.\n",
    "    agent_state_evo = []\n",
    "    for t in time_steps:\n",
    "        agent_state_evo.append(closed_loop_evolution[t][agents.index(agent)][\"current_state\"])\n",
    "    # Build state evolution matrix.\n",
    "    state_evo_mat = np.concatenate(agent_state_evo, axis=1)\n",
    "    \n",
    "    label_str = \"Agent \" + agent.id  # For labelling the plot.\n",
    "    \n",
    "    # Plot evolution of first states.\n",
    "    ax1.plot(time_steps, state_evo_mat[0, :], label=label_str, linestyle=line_styles[agents.index(agent)], linewidth=2)\n",
    "    ax1.minorticks_on()\n",
    "    ax1.legend()\n",
    "    \n",
    "    # Plot evolution of second states.\n",
    "    ax2.plot(time_steps, state_evo_mat[1, :], label=label_str, linestyle=line_styles[agents.index(agent)], linewidth=2)\n",
    "    ax2.minorticks_on()\n",
    "    ax2.legend()\n",
    "    \n",
    "    # Set line width of dotted trajectory to be larger in the last plot.\n",
    "    if line_styles[agents.index(agent)] == 'dotted':\n",
    "        line_width = 3\n",
    "    else:\n",
    "        line_width = 2\n",
    "        \n",
    "    # Plot 2D evolution.    \n",
    "    ax3.plot(state_evo_mat[0, :], state_evo_mat[1, :], label=label_str, linestyle=line_styles[agents.index(agent)], linewidth=line_width, color=colour_styles[agents.index(agent)])\n",
    "    # Plot last point.\n",
    "    ax3.plot(state_evo_mat[0, -1], state_evo_mat[1, -1], linestyle=line_styles[agents.index(agent)], linewidth=1, marker='x', color='k')\n",
    "#    ax3.minorticks_on()\n",
    "    ax3.legend()\n",
    "    \n",
    "# Add the constraint sets.\n",
    "ax3.axis('equal')  # Make plot a box.\n",
    "ax3.fill(agents[0].cooperation_output_constraint[\"vertex_mat\"][0,:], agents[0].cooperation_output_constraint[\"vertex_mat\"][1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0.1,0.1,0.1,0.05))  # Draw polyhedra.\n",
    "ax3.fill(agents[1].cooperation_output_constraint[\"vertex_mat\"][0,:], agents[1].cooperation_output_constraint[\"vertex_mat\"][1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0.1,0.1,0.1,0.05))  # Draw polyhedra.\n",
    "ax3.fill(agents[3].cooperation_output_constraint[\"vertex_mat\"][0,:], agents[3].cooperation_output_constraint[\"vertex_mat\"][1,:],\n",
    "         edgecolor='black', linewidth=2,\n",
    "         facecolor=(0.1,0.1,0.1,0.05))  # Draw polyhedra.\n",
    "ax3.grid(True, which='both')  # Draw grid lines.\n",
    "ax3.set_axisbelow(True)\n",
    "\n",
    "# Set axis labels.\n",
    "ax1.set_xlabel('time steps')\n",
    "ax1.set_ylabel('x_{i,1}')\n",
    "\n",
    "ax2.set_xlabel('time steps')\n",
    "ax2.set_ylabel('x_{i,2}')\n",
    "\n",
    "ax3.set_xlabel('x_{i,1}')\n",
    "ax3.set_ylabel('x_{i,2}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
